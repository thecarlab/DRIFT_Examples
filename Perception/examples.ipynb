{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv11n Object Detection Demo\n",
        "This notebook shows how to run the lightweight YOLOv11n detector on still images and a local webcam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install dependencies\n",
        "Run the cell below if ultralytics or OpenCV are missing from your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77fa5a68",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q ultralytics opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc94e594",
      "metadata": {},
      "source": [
        "## 2. Import libraries and load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147a7982",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "from urllib.request import urlretrieve\n",
        "from ultralytics import YOLO\n",
        "\n",
        "MODEL_DIR = Path(\"models\")\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "MODEL_WEIGHTS = MODEL_DIR / \"yolov8n.pt\"\n",
        "\n",
        "\n",
        "IMAGE_DIR = Path(\"demo_images\")\n",
        "IMAGE_DIR.mkdir(exist_ok=True)  # Keeps things organized for static assets\n",
        "\n",
        "model = YOLO(str(MODEL_WEIGHTS))\n",
        "device = getattr(model, \"device\", \"cpu\")\n",
        "CLASS_ID_LOOKUP = {name: idx for idx, name in model.names.items()}\n",
        "print(f\"Loaded {MODEL_WEIGHTS.name} on {device}\")\n",
        "print(f\"Drop sample images into {IMAGE_DIR.resolve()} before running detections.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e6fd3c",
      "metadata": {},
      "source": [
        "## 3. Download Ultralytics sample images (optional)\n",
        "Use this helper to pull the stock demo photos (`bus.jpg`, `zidane.jpg`) directly from the public Ultralytics assets repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb937f77",
      "metadata": {},
      "outputs": [],
      "source": [
        "ULTRALYTICS_SAMPLE_URLS = {\n",
        "    \"bus.jpg\": \"https://github.com/ultralytics/assets/releases/download/v0.0.0/bus.jpg\",\n",
        "    \"zidane.jpg\": \"https://github.com/ultralytics/assets/releases/download/v0.0.0/zidane.jpg\",\n",
        "}\n",
        "\n",
        "\n",
        "def download_ultralytics_samples(target_dir=IMAGE_DIR):\n",
        "    target_dir.mkdir(exist_ok=True)\n",
        "    for name, url in ULTRALYTICS_SAMPLE_URLS.items():\n",
        "        destination = target_dir / name\n",
        "        if destination.exists():\n",
        "            print(f\"{name} already exists, skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Downloading {name} ...\")\n",
        "        urlretrieve(url, destination)\n",
        "\n",
        "    print(f\"Samples saved to {target_dir.resolve()}\")\n",
        "\n",
        "\n",
        "# Run once to make sure the stock demo images are available locally.\n",
        "download_ultralytics_samples()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6faf961a",
      "metadata": {},
      "source": [
        "## 4. Detect objects in static images\n",
        "Place any `.jpg`, `.png`, or `.jpeg` files in `demo_images/` and execute the cell to render detections inline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1207a79e",
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "\n",
        "def run_on_images(conf=0.25):\n",
        "    images = sorted([p for p in IMAGE_DIR.iterdir() if p.suffix.lower() in IMAGE_EXTENSIONS])\n",
        "    if not images:\n",
        "        print(f\"Add some image files to {IMAGE_DIR.resolve()} and re-run this cell.\")\n",
        "        return\n",
        "\n",
        "    for image_path in images:\n",
        "        print(f\"\\nDetections for {image_path.name}\")\n",
        "        results = model.predict(image_path, conf=conf, verbose=False)\n",
        "        annotated = results[0].plot()  # Returns a BGR NumPy array\n",
        "        annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "        display(Image.fromarray(annotated_rgb))\n",
        "\n",
        "run_on_images(conf=0.25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bd6662",
      "metadata": {},
      "source": [
        "## 5. Filter detections by class\n",
        "This helper narrows detections to specific class names. The sample below keeps only the `tie` class for the stock `zidane.jpg` image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b669f87a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_filtered_detection(image_path, allowed_class_names, conf=0.25):\n",
        "    missing = [name for name in allowed_class_names if name not in CLASS_ID_LOOKUP]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Unknown class names: {missing}\")\n",
        "\n",
        "    allowed_ids = [CLASS_ID_LOOKUP[name] for name in allowed_class_names]\n",
        "    results = model.predict(image_path, classes=allowed_ids, conf=conf, verbose=False)\n",
        "    annotated = results[0].plot()\n",
        "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "    display(Image.fromarray(annotated_rgb))\n",
        "\n",
        "\n",
        "target_image = IMAGE_DIR / \"zidane.jpg\"\n",
        "if target_image.exists():\n",
        "    print(f\"Showing only 'tie' detections for {target_image.name}\")\n",
        "    run_filtered_detection(target_image, [\"tie\"])\n",
        "else:\n",
        "    print(f\"{target_image} is missing. Download the Ultralytics samples cell above and re-run.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d237db57",
      "metadata": {},
      "source": [
        "## 6. Detect objects from a local webcam\n",
        "This helper streams frames from the camera, annotates them, and displays them in an OpenCV window. Press **q** to exit the stream."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_webcam(conf=0.25, webcam_index=0, window_name=\"YOLOv11n Webcam\"):\n",
        "    cap = cv2.VideoCapture(webcam_index)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Unable to open webcam index {webcam_index}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Failed to grab frame\")\n",
        "                break\n",
        "\n",
        "            results = model.predict(frame, conf=conf, verbose=False)\n",
        "            annotated = results[0].plot()\n",
        "            cv2.imshow(window_name, annotated)\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Uncomment to start streaming once you are ready.\n",
        "# run_webcam(conf=0.25, webcam_index=0)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
